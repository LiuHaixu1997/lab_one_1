{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'australian_scale.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-44c9c3123214>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 数据读取\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_svmlight_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"australian_scale.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# 数据切分\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\sklearn\\datasets\\svmlight_format.py\u001b[0m in \u001b[0;36mload_svmlight_file\u001b[1;34m(f, n_features, dtype, multilabel, zero_based, query_id, offset, length)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \"\"\"\n\u001b[0;32m    146\u001b[0m     return tuple(load_svmlight_files([f], n_features, dtype, multilabel,\n\u001b[1;32m--> 147\u001b[1;33m                                      zero_based, query_id, offset, length))\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\sklearn\\datasets\\svmlight_format.py\u001b[0m in \u001b[0;36mload_svmlight_files\u001b[1;34m(files, n_features, dtype, multilabel, zero_based, query_id, offset, length)\u001b[0m\n\u001b[0;32m    288\u001b[0m     r = [_open_and_load(f, dtype, multilabel, bool(zero_based), bool(query_id),\n\u001b[0;32m    289\u001b[0m                         offset=offset, length=length)\n\u001b[1;32m--> 290\u001b[1;33m          for f in files]\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     if (zero_based is False or\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\sklearn\\datasets\\svmlight_format.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    288\u001b[0m     r = [_open_and_load(f, dtype, multilabel, bool(zero_based), bool(query_id),\n\u001b[0;32m    289\u001b[0m                         offset=offset, length=length)\n\u001b[1;32m--> 290\u001b[1;33m          for f in files]\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     if (zero_based is False or\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\sklearn\\datasets\\svmlight_format.py\u001b[0m in \u001b[0;36m_open_and_load\u001b[1;34m(f, dtype, multilabel, zero_based, query_id, offset, length)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;31m# XXX remove closing when Python 2.7+/3.1+ required\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_gen_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             \u001b[0mactual_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 _load_svmlight_file(f, dtype, multilabel, zero_based, query_id,\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\sklearn\\datasets\\svmlight_format.py\u001b[0m in \u001b[0;36m_gen_open\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mBZ2File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'australian_scale.txt'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "\n",
    "\n",
    "# 数据读取\n",
    "data = load_svmlight_file(\"australian_scale.txt\")\n",
    "# 数据切分\n",
    "data_train, data_test, value_train, value_test = train_test_split(data[0], data[1], test_size=0.33)\n",
    "\n",
    "# 初始化\n",
    "learning_rate = 0.0005\n",
    "initial_w = random.random(size=(15, 1))\n",
    "num_iter = 1000\n",
    "\n",
    "# 偏移值\n",
    "bias_train = np.mat(np.ones(shape=[data_train.shape[0], 1]))\n",
    "bias_train = csr_matrix(bias_train).todense()\n",
    "\n",
    "bias_test = np.mat(np.ones(shape=[data_test.shape[0], 1]))\n",
    "bias_test = csr_matrix(bias_test).todense()\n",
    "\n",
    "# 训练集矩阵\n",
    "x_mat_train = csr_matrix(data_train).todense()\n",
    "x_mat_train = np.hstack((x_mat_train, bias_train))\n",
    "\n",
    "y_train = np.mat(value_train).T\n",
    "y_mat_train = csr_matrix(y_train).todense()\n",
    "\n",
    "# 验证集矩阵\n",
    "x_mat_test = csr_matrix(data_test).todense()\n",
    "x_mat_test = np.hstack((x_mat_test, bias_test))\n",
    "\n",
    "y_test = np.mat(value_test).T\n",
    "y_mat_test = csr_matrix(y_test).todense()\n",
    "\n",
    "# 求梯度\n",
    "initial_w = csr_matrix(initial_w).todense()\n",
    "# gradient = - np.dot(x_mat_train.T, y_mat_train) + np.dot(np.dot(x_mat_train.T, x_mat_train), initial_w)\n",
    "# d = - gradient\n",
    "# c = random.random(size=(1, 15))\n",
    "gradient_list = []\n",
    "for i in range(x_mat_train.shape[0]):\n",
    "    a = np.dot(initial_w.T, x_mat_train[0].T)\n",
    "    b = np.dot(y_mat_train[0], a)\n",
    "    if b[0] < 1:\n",
    "        gw_train = - np.dot(y_mat_train[0], x_mat_train[0])\n",
    "    else:\n",
    "        gw_train = 0\n",
    "    gradient_list.append(gw_train)\n",
    "c = choice(gradient_list)\n",
    "gradient = initial_w + 0.9 * c\n",
    "w = initial_w\n",
    "d = - gradient\n",
    "# 用列表表示每一次迭代的损失率\n",
    "loss_list_train = []\n",
    "loss_list_test = []\n",
    "\n",
    "# 梯度下降\n",
    "for j in range(num_iter):\n",
    "    # w，d的迭代更新\n",
    "    w = w + learning_rate * d\n",
    "    for k in range(x_mat_train.shape[0]):\n",
    "        a = np.dot(w.T, x_mat_train[0].T)\n",
    "        b = np.dot(y_mat_train[0], a)\n",
    "        if b[0] < 1:\n",
    "            gw_train = - np.dot(y_mat_train[0], x_mat_train[0])\n",
    "        else:\n",
    "            gw_train = 0\n",
    "        c = choice(gradient_list)\n",
    "    gradient = w + 0.9 * c\n",
    "    # d_test = np.dot(x_mat_test.T, y_mat_test) - np.dot(np.dot(x_mat_test.T, x_mat_test), w)\n",
    "\n",
    "    loss_train = np.dot((y_mat_train - np.dot(x_mat_train, w)).T, (y_mat_train - np.dot(x_mat_train, w))) / 2 / 339\n",
    "    loss_test = np.dot((y_mat_test - np.dot(x_mat_test, w)).T, (y_mat_test - np.dot(x_mat_test, w))) / 2 / 167\n",
    "\n",
    "    loss_list_train.append(loss_train.tolist()[0][0])\n",
    "    loss_list_test.append(loss_test.tolist()[0][0])\n",
    "\n",
    "# 图像输出\n",
    "plt.plot(np.arange(0, num_iter), loss_list_train, label=u'train')\n",
    "plt.plot(np.arange(0, num_iter), loss_list_test, label=u'validation')\n",
    "plt.legend()\n",
    "plt.title(u'linear classification')\n",
    "plt.xlabel(u\"iteration times\")\n",
    "plt.ylabel(u\"loss ratio\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 线性分类\n",
    "negative_class = []\n",
    "positive_class = []\n",
    "for i in range(x_mat_train.shape[0]):\n",
    "    hyperplane = np.dot(w.T, x_mat_train[i].T).tolist()\n",
    "    if hyperplane[0][0] > 0:\n",
    "        positive_class.append(hyperplane[0][0])\n",
    "    else:\n",
    "        negative_class.append(hyperplane[0][0])\n",
    "print(\"positive class is: \", positive_class)\n",
    "print(\"/n/n/n/n\")\n",
    "print(\"negative class is: \", negative_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
